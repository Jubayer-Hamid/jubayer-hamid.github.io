<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jubayer Ibn Hamid</title>
  
  <meta name="author" content="Jubayer Ibn Hamid">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Jubayer Ibn Hamid</name>
              </p>
              <p> Hi! I am an undergraduate at <a href="https://www.stanford.edu">Stanford University</a> studying Mathematical Physics and a researcher at <a href="https://ai.stanford.edu">Stanford Artificial Intelligence Laboratory (SAIL)</a>. I am fortunate to have my research advised by Professor <a href="https://ai.stanford.edu/~cbfinn/">Chelse Finn</a>. 

                Previously, I did research in theoretical and experimental physics, particularly in the fields of quantum field theory and material physics. 
              <p style="text-align:center">
                <a href="mailto:jubayer@stanford.edu">Email</a> &nbsp/&nbsp
                <a href="https://twitter.com/jubayer_hamid">Twitter</a> &nbsp/&nbsp
                <!-- <a href="https://github.com/Jubayer-Hamid">LinkedIn</a> &nbsp/&nbsp -->
                <a href="https://github.com/Jubayer-Hamid">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/jubayer.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/jubayer_circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
              I am broadly interested in researching scalable methods for helping robots acquire complex behaviours through learning. To that end, I am also interested in adjacent fields such as generative AI and optimisation. I am currently working on disentangled representation learning. 
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src='images/pvrs.png' width="160">
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://kayburns.github.io/segmentingfeatures/">
                <papertitle>WHAT MAKES PRE-TRAINED VISUAL REPRESENTATIONS SUCCESSFUL
                  FOR ROBUST MANIPULATION?</papertitle>
              </a>
              <br>
              <a href="https://kayburns.github.io">Kaylee Burns</a>,
              <a href="">Zach Witzel</a>, 
              <strong>Jubayer Ibn Hamid</strong>,
              <a href="">Tianhe Yu</a>, 
              <a href="https://deqings.github.io/">Chelsea Finn</a>, 
              <a href="">Karol Hausman</a>
              <br>
              <a href="https://kayburns.github.io/segmentingfeatures/static/segmentingfeatures_paper.pdf">Paper</a> /
              <a href="https://kayburns.github.io/segmentingfeatures/">Website</a>
              <p>
                We find that visual representations designed for manipulation and control tasks do not necessarily generalize under subtle changes in lighting and scene texture or the introduction of distractor objects. To understand what properties do lead to robust representations, we compare the performance of 15 pre-trained vision models under different visual appearances. We find that emergent segmentation ability is a strong predictor of out-of-distribution generalization among ViT models. The rank order induced by this metric is more predictive than metrics that have previously guided generalization research within computer vision and machine learning, such as downstream ImageNet accuracy, in-domain accuracy, or shape-bias as evaluated by cue-conflict performance.
              </p>
            </td>
          </tr>		
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;">
                <a href="https://jonbarron.info/">Template</a>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
